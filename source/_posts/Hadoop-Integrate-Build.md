---
title: å¤§æ•°æ®ä¹‹è·¯ Hadoop ç¯å¢ƒæ­å»º
date: 2017-11-22 10:36:07
description: è™½ç„¶è¯´ Hadoop çš„ç¯å¢ƒåœ¨æˆ‘æœ¬åœ°æ—©å°±æ­å»ºå¥½äº†,ç°åœ¨å›æƒ³èµ·æ¥,è¿˜æ˜¯æœ‰ç‚¹å‘çš„,åœ¨è¿™é‡Œè®°å½•ä¸€ä¸‹å§
categories: [å¤§æ•°æ®ç¯‡]
tags: [Hadoop]
---

<!-- more -->
## é¦–å…ˆ
é¦–å…ˆè¦è¯´æ˜çš„æ˜¯,æœ¬ç¯‡æ–‡ç« ç”¨çš„ Hadoop çš„ç‰ˆæœ¬éƒ½æ˜¯ç›®å‰æœ€æ–°ç‰ˆ,ç›´æ¥åœ¨å®˜ç½‘ä¸Šä¸‹è½½å°±å¯ä»¥äº†
æœ‰äº›å‘½ä»¤å¯èƒ½å·²ç»ä¸é€‚åº”ä¹‹å‰çš„æ—§ç‰ˆæœ¬äº†,ä»¥æœ€æ–°çš„ç‰ˆçš„ä¸ºå‡†
ä»¥ä¸‹æ“ä½œå‘½ä»¤å‡æ˜¯åœ¨æœåŠ¡çš„æ ¹ç›®å½•ä¸‹,ä½¿ç”¨çš„æ˜¯ç›¸å¯¹ç›®å½•

### å½“å‰ç‰ˆæœ¬è¯´æ˜
- Hadoop ç‰ˆæœ¬2.8.0
- æ“ä½œç³»ç»Ÿç‰ˆæœ¬ centos 7.2

## é¦–å…ˆéœ€è¦åšçš„
å®‰è£… jdk ç¯å¢ƒ,å†æ­¤ä¸åšè¯¦ç»†å™è¿°äº†,éœ€è¦æ³¨æ„çš„æ˜¯ jdk çš„ç¯å¢ƒå˜é‡çš„é…ç½®

`yum install openjdk1.8xxxxx` è¿™ä¸ªå®‰è£…çš„æ˜¯ jreç¯å¢ƒ,å¹¶ä¸æ˜¯ jdk,å®‰è£… jdk

``` shell
    sudo yum install java-1.7.0-openjdk java-1.8.0-openjdk-devel
```

é…ç½®ç¯å¢ƒå˜é‡

``` shell
    vim ~/.bashrc
```

æœ€åä¸€è¡Œæ·»åŠ 

``` shell
    export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
```

ç´§æ¥ç€,è®©ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ

``` shell
    source ~/.bashrc    # ä½¿å˜é‡è®¾ç½®ç”Ÿæ•ˆ
```

è®¾ç½®å¥½ä¹‹å,å†çœ‹ä¸‹æ˜¯å¦ç”Ÿæ•ˆäº†

``` cmd
    echo $JAVA_HOME     # æ£€éªŒå˜é‡å€¼
    java -version
    $JAVA_HOME/bin/java -version  # ä¸ç›´æ¥æ‰§è¡Œ java -version ä¸€æ ·å°±æ²¡ä»€ä¹ˆé—®é¢˜äº†
```

## Hadoop å•æœºç¯å¢ƒæ­å»ºåŠæµ‹è¯•è¿è¡Œ
å®˜ç½‘ä¸‹è½½ Hadoop åŒ…

ä¸Šä¼ åˆ°æœåŠ¡å™¨ä¸Š,è§£å‹ tar -zxf hadoop-2.8.2.tar.gz
è§£å‹å®Œäº†,æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ä¸‹ç‰ˆæœ¬ä¿¡æ¯

``` cmd
    bin/hadoop version
    
    Hadoop 2.8.2
    Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb
    Compiled by jdu on 2017-10-19T20:39Z
    Compiled with protoc 2.5.0
    From source with checksum dce55e5afe30c210816b39b631a53b1d
    This command was run using /home/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar
```

å‡ºç°ä¸Šè¿°ä¿¡æ¯å°±æ²¡æœ‰ä»€ä¹ˆé—®é¢˜

æ¥ä¸‹æ¥,å°±å¯ä»¥è¿è¡Œ Hadoop è‡ªå¸¦çš„åˆ—å­äº†,ä¾‹å­çš„ç›®å½•åœ¨ /share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.0.jar

``` cmd
    // åˆ›å»º1ä¸ªè¾“å…¥ç›®å½•,è¾“å‡ºç›®å½•ä¸ç”¨åˆ›å»º,åœ¨å‘½ä»¤ä¸­ä¼šè‡ªåŠ¨åˆ›å»º,å¦‚æœåˆ›å»ºäº†,ä¼šæç¤ºç›®å½•å·²ç»å­˜åœ¨,å†æ¬¡è¿è¡Œç¤ºä¾‹ç¨‹åºåŒ–,åˆ é™¤è¾“å‡ºç›®å½•å³å¯
    mkdir ./input
    
    // çœ‹çœ‹éƒ½æœ‰å“ªäº›ä¾‹å­
    ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar
    
    An example program must be given as the first argument.
    Valid program names are:
      aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
      aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
      bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
      dbcount: An example job that count the pageview counts from a database.
      distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
      grep: A map/reduce program that counts the matches of a regex in the input.
      join: A job that effects a join over sorted, equally partitioned datasets
      multifilewc: A job that counts words from several files.
      pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
      pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.
      randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.
      randomwriter: A map/reduce program that writes 10GB of random data per node.
      secondarysort: An example defining a secondary sort to the reduce.
      sort: A map/reduce program that sorts the data written by the random writer.
      sudoku: A sudoku solver.
      teragen: Generate data for the terasort
      terasort: Run the terasort
      teravalidate: Checking results of terasort
      wordcount: A map/reduce program that counts the words in the input files.
      wordmean: A map/reduce program that counts the average length of the words in the input files.
      wordmedian: A map/reduce program that counts the median length of the words in the input files.
      wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.
```

æ¥ä¸‹æ¥,è·‘ä¸€ä¸ªç»å…¸çš„ wordcount ,å†æ¬¡ä¹‹å‰,æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ–‡æœ¬ä»¥ä¾›ç¨‹åºç»Ÿè®¡

``` cmd
    cat input/test.txt
    vi input/test.txt
    
    æ’å…¥ä¸€äº›å­—ç¬¦
```

å¼€å§‹è®°å½•

``` cmd
    ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar wordcount ./input/test.txt ./output/
```

æˆªå–éƒ¨åˆ†è¾“å‡º

``` txt
    17/11/22 11:30:08 INFO mapred.LocalJobRunner: reduce > reduce
    17/11/22 11:30:08 INFO mapred.Task: Task 'attempt_local1247748922_0001_r_000000_0' done.
    17/11/22 11:30:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1247748922_0001_r_000000_0
    17/11/22 11:30:08 INFO mapred.LocalJobRunner: reduce task executor complete.
    17/11/22 11:30:08 INFO mapreduce.Job: Job job_local1247748922_0001 running in uber mode : false
    17/11/22 11:30:08 INFO mapreduce.Job:  map 100% reduce 100%
    17/11/22 11:30:08 INFO mapreduce.Job: Job job_local1247748922_0001 completed successfully
    17/11/22 11:30:08 INFO mapreduce.Job: Counters: 30
    	File System Counters
    		FILE: Number of bytes read=605002
    		FILE: Number of bytes written=1267054
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    	Map-Reduce Framework
    		Map input records=38
    		Map output records=35
    		Map output bytes=277
    		Map output materialized bytes=251
    		Input split bytes=103
    		Combine input records=35
    		Combine output records=23
    		Reduce input groups=23
    		Reduce shuffle bytes=251
    		Reduce input records=23
    		Reduce output records=23
    		Spilled Records=46
    		Shuffled Maps =1
    		Failed Shuffles=0
    		Merged Map outputs=1
    		GC time elapsed (ms)=21
    		Total committed heap usage (bytes)=461250560
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters
    		Bytes Read=140
    	File Output Format Counters
    		Bytes Written=165
```

çœ‹ä¸‹è¾“å‡ºæƒ…å†µ

``` xml
    # cat output/*
    hello	1
    jjjjj	1
    joylau	2
    world	1
```

å¯ä»¥çœ‹åˆ°æ¯ä¸ªå•è¯å‡ºç°çš„æ¬¡æ•°

## Hadoop ä¼ªåˆ†å¸ƒå¼ç¯å¢ƒæ­å»º
æˆ‘ä»¬éœ€è¦è®¾ç½® HADOOP ç¯å¢ƒå˜é‡

``` cmd
    gedit ~/.bashrc
    
    export HADOOP_HOME=/home/hadoop-2.8.0
    export HADOOP_INSTALL=$HADOOP_HOME
    export HADOOP_MAPRED_HOME=$HADOOP_HOME
    export HADOOP_COMMON_HOME=$HADOOP_HOME
    export HADOOP_HDFS_HOME=$HADOOP_HOME
    export YARN_HOME=$HADOOP_HOME
    export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
    export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
    
    source ~/.bashrc
    
```

ä¿®æ”¹é…ç½®æ–‡ä»¶
### core-site.xml
``` xml
    <configuration>
      <property>
            <name>hadoop.tmp.dir</name>
            <value>file:/home/temp</value>
            <description>Abase for other temporary directories.</description>
        </property>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://localhost:9000</value>
        </property>
    </configuration>
```

### hdfs-site.xml
``` xml
    <configuration>
     <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
        <property>
            <name>dfs.namenode.name.dir</name>
            <value>file:/home/temp/hdfs/namenode</value>
        </property>
        <property>
            <name>dfs.datanode.data.dir</name>
            <value>file:/home/temp/hdfs/datanode</value>
        </property>
    </configuration>
```

é…ç½®å®Œæˆåï¼Œæ‰§è¡Œ NameNode å’Œ DataNode çš„æ ¼å¼åŒ–:

``` cmd
    ./bin/hdfs namenode -format
    ./bin/hdfs datanode -format
```

ç°åœ¨å¯åŠ¨ Hadoop ä¼ªåˆ†å¸ƒå¼æœåŠ¡å™¨

``` cmd
    ./sbin/start-dfs.sh 
    ./sbin/start-yarn.sh
```

ä»¥å‰ç‰ˆæœ¬çš„å‘½ä»¤æ˜¯

``` cmd
    ./sbin/start-all.sh
```

jpsæŸ¥çœ‹å¯åŠ¨æ˜¯å¦æˆåŠŸå¯åŠ¨

``` cmd
    jps
    
    5360 Jps
    4935 ResourceManager
    5225 NodeManager
    4494 NameNode
    4782 SecondaryNameNode
```

æˆåŠŸå¯åŠ¨åï¼Œå¯ä»¥è®¿é—® Web ç•Œé¢ http://localhost:50070 æŸ¥çœ‹ NameNode å’Œ Datanode ä¿¡æ¯ï¼Œè¿˜å¯ä»¥åœ¨çº¿æŸ¥çœ‹ HDFS ä¸­çš„æ–‡ä»¶
è¿è¡Œ stop-all.sh æ¥å…³é—­æ‰€æœ‰è¿›ç¨‹

## ä¼ªåˆ†å¸ƒå¼ç¯å¢ƒå®ä¾‹è¿è¡Œ
ä¸Šé¢å®ä¾‹çš„è¿è¡Œæ—¶å•æœºç‰ˆçš„,ä¼ªåˆ†å¸ƒå¼çš„å®ä¾‹çš„è¿è¡Œçš„ä¸åŒä¹‹å¤„åœ¨äº,è¯»å–æ–‡ä»¶æ˜¯åœ¨ HDFS ä¸Šçš„

æŒ‰ç…§å¸¸è§„çš„å°¿æ€§,æˆ‘ä»¬å…ˆåˆ›å»ºä¸ªç”¨æˆ·ç›®å½• ,ä»¥åå°±å¯ä»¥ä»¥ç›¸å¯¹ç›®å½•æ¥è¿›è¡Œæ–‡ä»¶çš„æ“ä½œäº†

è¿™é‡Œå¾—è¯´ä¸‹ hdfs çš„å¸¸ç”¨ shell

- åˆ›å»ºç›®å½• `./bin/hdfs dfs -mkdir -p /user/root`
- ä¸Šä¼ æ–‡æ¡£ `./bin/hdfs dfs -put ./input/test.txt input`
- åˆ é™¤æ–‡æ¡£ `./bin/hdfs dfs -rmr input`
- äº§çœ‹æ–‡æ¡£ `./bin/hdfs dfs -cat input/*`
- æŸ¥çœ‹åˆ—è¡¨ `./bin/hdfs dfs -ls input`
- æ‹‰å–æ–‡æ¡£ `./bin/hdfs dfs -get output/* ./output`

æœ‰äº†è¿™äº›ç®€å•çš„å‘½ä»¤,ç°åœ¨å°±å¯ä»¥è¿è¡Œå®ä¾‹

å…ˆåˆ›å»ºç”¨æˆ·ç›®å½• `./bin/hdfs dfs -mkdir -p /user/root`
åœ¨æ–°å»ºä¸€ä¸ªç›®å½• `./bin/hdfs dfs -mkdir input`
å°†ä¹‹å‰çš„æ–‡ä»¶ä¸Šä¼  `./bin/hdfs dfs -put ./input/test.txt input`
ä¸Šä¼ æˆåŠŸåè¿˜å¯ä»¥æŸ¥çœ‹ä¸‹æ—¶å€™æœ‰æ–‡ä»¶ `./bin/hdfs dfs -ls input`
è¿è¡Œå®ä¾‹  `./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar wordcount input/ output/`
æŸ¥çœ‹è¿è¡Œç»“æœ `./bin/hdfs dfs -cat output/*`

å…¶å®è¿™äº›å‘½ä»¤éƒ½æ˜¯ç±» linux å‘½ä»¤,ç†Ÿæ‚‰ linux å‘½ä»¤,è¿™äº›éƒ½å¾ˆå¥½æ“ä½œ

å¯ä»¥çœ‹åˆ°ç»Ÿè®¡ç»“æœå’Œå•æœºç‰ˆæ˜¯ä¸€è‡´çš„

å°†ç»“æœå¯¼å‡º `./bin/hdfs dfs -get output ./output`

å…¶å® åœ¨ http://host:50070/explorer.html#/user/root å¯ä»¥çœ‹åˆ°ä¸Šä¼ å’Œè¾“å‡ºçš„æ–‡ä»¶ç›®å½•

### YARN å¯åŠ¨
ä¼ªåˆ†å¸ƒå¼ä¸å¯åŠ¨ YARN ä¹Ÿå¯ä»¥ï¼Œä¸€èˆ¬ä¸ä¼šå½±å“ç¨‹åºæ‰§è¡Œ
YARN æ˜¯ä» MapReduce ä¸­åˆ†ç¦»å‡ºæ¥çš„ï¼Œè´Ÿè´£èµ„æºç®¡ç†ä¸ä»»åŠ¡è°ƒåº¦ã€‚YARN è¿è¡Œäº MapReduce ä¹‹ä¸Šï¼Œæä¾›äº†é«˜å¯ç”¨æ€§ã€é«˜æ‰©å±•æ€§

é¦–å…ˆä¿®æ”¹é…ç½®æ–‡ä»¶ mapred-site.xmlï¼Œè¿™è¾¹éœ€è¦å…ˆè¿›è¡Œé‡å‘½åï¼š

``` cmd
    mv ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml
```

å¢åŠ é…ç½®

``` xml
    <configuration>
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
    </configuration>
```

é…ç½®æ–‡ä»¶ yarn-site.xmlï¼š

``` xml
    <configuration>
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
            </property>
    </configuration>
```

``` cmd
    ./sbin/start-yarn.sh      $ å¯åŠ¨YARN
    ./sbin/mr-jobhistory-daemon.sh start historyserver  # å¼€å¯å†å²æœåŠ¡å™¨ï¼Œæ‰èƒ½åœ¨Webä¸­æŸ¥çœ‹ä»»åŠ¡è¿è¡Œæƒ…å†µ
```

å¯åŠ¨ YARN ä¹‹åï¼Œè¿è¡Œå®ä¾‹çš„æ–¹æ³•è¿˜æ˜¯ä¸€æ ·çš„ï¼Œä»…ä»…æ˜¯èµ„æºç®¡ç†æ–¹å¼ã€ä»»åŠ¡è°ƒåº¦ä¸åŒã€‚
è§‚å¯Ÿæ—¥å¿—ä¿¡æ¯å¯ä»¥å‘ç°ï¼Œä¸å¯ç”¨ YARN æ—¶ï¼Œæ˜¯ â€œmapred.LocalJobRunnerâ€ åœ¨è·‘ä»»åŠ¡ï¼Œ
å¯ç”¨ YARN ä¹‹åï¼Œæ˜¯ â€œmapred.YARNRunnerâ€ åœ¨è·‘ä»»åŠ¡ã€‚
å¯åŠ¨ YARN æœ‰ä¸ªå¥½å¤„æ˜¯å¯ä»¥é€šè¿‡ Web ç•Œé¢æŸ¥çœ‹ä»»åŠ¡çš„è¿è¡Œæƒ…å†µï¼šhttp://localhost:8088/cluster

## è¸©å‘è®°å½•
- å†…å­˜ä¸è¶³:ä¸€å¼€å§‹è™šæ‹Ÿæœºåªå¼€äº†2G å†…å­˜,å‡ºç°äº†å¾ˆå¤šé”™è¯¯,åæ¥å°†è™šæ‹Ÿæœºå†…å­˜å¼€åˆ°8G, å°±æ²¡æœ‰é—®é¢˜äº†
- hosts é…ç½®,ä¸€å¼€å§‹å¯åŠ¨çš„æ—¶å€™ä¼šæŠ¥ä¸è¯†åˆ« localhost çš„åŸŸåçš„é”™è¯¯,æ›´æ”¹ä¸‹ hostsæ–‡ä»¶å³å¯,åŠ ä¸€è¡Œ

``` xml
    127.0.0.1   localhost HostName
```

### å‚è€ƒèµ„æ–™
ã€ŠHadoop æƒå¨æŒ‡å— : ç¬¬å››ç‰ˆã€‹ --Tom White è‘—

### æ„Ÿå—
è¿™ç¯‡æ–‡ç« å†™ä¸‹æ¥ç­‰äºå°†å½“æ—¶æ­å»º Hadoop ç¯å¢ƒé‡å¤äº†ä¸€é,èŠ±äº†ä¸å°‘åŠŸå¤«çš„,ä¸€éæ•²å‘½ä»¤,ä¸€éè®°å½•ä¸‹æ¥,æ¸©æ•…è€ŒçŸ¥æ–°,è‡ªå·±ä¹Ÿå­¦åˆ°ä¸å°‘ä¸œè¥¿,æ£’æ£’å“’ğŸ’¯